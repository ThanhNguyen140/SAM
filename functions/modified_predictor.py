from typing import Optional, Tuple
from segment_anything.utils.transforms import ResizeLongestSide
from segment_anything import SamPredictor, sam_model_registry
import torch
from torch._tensor import Tensor

DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
MODEL_TYPE = "vit_h"
CHECKPOINT_PATH = "../sam_vit_h_4b8939.pth"
sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH)
sam.to(device=DEVICE)


class modifiedPredictor:
    """Subclass of SamPredictor class. This class allows the generation of masks with the same syntax as the parent class for predict function
    using image embeddings
    """

    def __init__(self, image_embedding, input_size, original_size, sam_model=sam):
        """Input for subclass of SamPredictor

        Args:
            image_embedding (NDArray): An image embedding generated by the parent class by set_image
            input_size (tuple): a tuple containing size of image before generating embeddings. This is not
            the orginal size of image because the image is resized according to sam model before generating embeddings
            original_size (tuple): original size of the image in 2D (H x W)
            sam_model (sam model, optional): Defaults to sam.
        """
        super().__init__(sam_model)
        self.transform = ResizeLongestSide(sam_model.image_encoder.img_size)
        self.is_image_set = True
        self.input_size = input_size
        self.original_size = original_size
        self.features = image_embedding

    def predict2(self,image_embeddings, point_coords,point_labels, multimask_output=False):
        point_coords = self.transform.apply_coords(point_coords, self.original_size)
        coords_torch = torch.as_tensor(point_coords, dtype=torch.float, device=self.device)
        labels_torch = torch.as_tensor(point_labels, dtype=torch.int, device=self.device)
        coords_torch, labels_torch = coords_torch[None, :, :], labels_torch[None, :]
        box_torch,mask_input_torch = None,None
        masks, iou_predictions, low_res_masks = self.predict_torch(
            coords_torch,
            labels_torch,
            box_torch,
            mask_input_torch,
            multimask_output,
            return_logits=True,
        )
        return masks
